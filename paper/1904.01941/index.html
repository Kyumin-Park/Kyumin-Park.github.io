<!doctype html>
<html lang="en-us">
  <head>
    <title>Character Region Awareness for Text Detection // Notespace</title>
    <link rel="shortcut icon" href="/images/default/cat.jpg" />
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.80.0" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Kyumin Park" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="https://kyumin-park.github.io/css/main.min.11035e2a4fa928eb3cf3a1d797eaac7a8e0315b79d38bb9644a50b22e0ac3c30.css" />

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Character Region Awareness for Text Detection"/>
<meta name="twitter:description" content="OCR OCR은 많은 경우 Text Detection과 Text Recognition의 두 부분으로 나눌 수 있다. 두 task의 목적을 간단히 정리하면, &lsquo;텍스"/>

    <meta property="og:title" content="Character Region Awareness for Text Detection" />
<meta property="og:description" content="OCR OCR은 많은 경우 Text Detection과 Text Recognition의 두 부분으로 나눌 수 있다. 두 task의 목적을 간단히 정리하면, &lsquo;텍스" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://kyumin-park.github.io/paper/1904.01941/" />
<meta property="article:published_time" content="2021-01-04T01:34:05+09:00" />
<meta property="article:modified_time" content="2021-01-04T01:34:05+09:00" />


  </head>
  <body>
    <header class="app-header">
      <a href="https://kyumin-park.github.io"><img class="app-header-avatar" src="/images/default/cat.jpg" alt="Kyumin Park" /></a>
      <h3>Kyumin Park</h3>
      <p>M.S. Student in DEAL@KAIST</p>
      <div class="app-header-social">
        
          <a target="_blank" href="https://github.com/Kyumin-Park" rel="noreferrer noopener"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-github">
  <title>github</title>
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"></path>
</svg></a>
        
          <a target="_blank" href="https://www.linkedin.com/in/kyumin-park-6b2431195/" rel="noreferrer noopener"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-linkedin">
  <title>linkedin</title>
  <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z"></path><rect x="2" y="9" width="4" height="12"></rect><circle cx="4" cy="4" r="2"></circle>
</svg></a>
        
          <a target="_blank" href="pkm9403@gmail.com" rel="noreferrer noopener"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-mail">
  <title>mail</title>
  <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"></path><polyline points="22,6 12,13 2,6"></polyline>
</svg></a>
        
      </div>
      <nav class="app-header-menu">
        <ul class="menu-items">
          <li><a class="app-header-menu-item" href="/">Home</a></li>
          <li><a class="app-header-menu-item" href="/paper">Papers</a></li>
          <li><a class="app-header-menu-item" href="/categories/">Categories</a></li>
        </ul>
      </nav>


    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">Character Region Awareness for Text Detection</h1>
      <div class="post-meta">
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          Jan 4, 2021
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          4 min read
        </div>
        <div>
          <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line>
</svg>
              <a class="tag" href="https://kyumin-park.github.io/tags/ocr/">OCR</a>
        </div>
      </div>
    </header>
    <div class="post-content">
      <h1 id="ocr">OCR</h1>
<p>OCR은 많은 경우 Text Detection과 Text Recognition의 두 부분으로 나눌 수 있다.
두 task의 목적을 간단히 정리하면, &lsquo;텍스트가 어디 있나&rsquo;, &lsquo;텍스트가 무엇인가&rsquo;의 답을 구하는 것이라 할 수 있다.
CRAFT 논문은 그 중 Text Detection을 다룬 것으로, 기존의 Word 단위의 detection을 벗어나 character 단위의 detection을 제안한다.</p>
<h1 id="architecture">ARCHITECTURE</h1>
<div style="text-align: center;">
<figure >
    
        <img src="/images/paper/craft/craft_1.png" />
    
    <figcaption><small><i>CRAFT 모델 구조</i></small></figcaption>
</figure>
</div>
<p>모델은 VGG-16의 구조를 backbone으로 사용했고, U-Net과 유사한 형태를 띠게 된다.
아무래도 Semantic segmentation과 같이 픽셀 단위 heatmap 예측을 하기 때문에 해당 구조를 사용했을 것이라 생각한다.
특이한 점은 마지막에 score로 Region score과 Affinity score로 이름지어진 두 개의 heatmap을 생성하는데,
region score는 각 character의 위치를, affinity score는 character의 연결 상태를 heatmap으로 나타내었다 볼 수 있다.</p>
<h1 id="ground-truth">Ground Truth</h1>
<div style="text-align: center;">
<figure >
    
        <img src="/images/paper/craft/craft_2.png" />
    
    <figcaption><small><i>Ground truth 생성 과정</i></small></figcaption>
</figure>
</div>
<p>사실 비교적 단순하게 보이는 (U-net과 유사한 형태이기 때문에) 모델 구조보다는 학습을 한 방법이 이 논문에서 더 중점적으로 다뤄졌고,
다른 기존 text detection 방법에 비해 신선하다 할 수 있을 것으로 보인다. 각각의 글자에 대한 score map을 새로 정의했고,
따라서 미리 주어진 것이 없기 때문에 학습을 할 때 ground truth heatmap을 직접 제작해야 한다.
이 때 저자는 기존 데이터셋 중 character 단위로 box annotation이 되어 있는 데이터셋을 활용한다.
각각의 character box에 2D Gaussian map을 warping해서 박스에 맞춘 후, 해당 위치에 집어넣어 ground truth로 만든 것이다.
Affinity score의 경우에는 affinity box 또한 없기 때문에 box를 만드는 과정부터 시작했다. 이어진 두 character box에 대각선을 그어,
만들어진 두 삼각형 (위아래로 있는)의 중심을 구하고, 구해진 네 점을 이어 affinity box로 만들었다.
그 후 character box와 같은 과정을 거치면 affinity score heatmap도 만들 수 있다.</p>
<h1 id="weakly-supervised-learning">Weakly Supervised Learning</h1>
<div style="text-align: center;">
<figure >
    
        <img src="/images/paper/craft/craft_3.png" />
    
    <figcaption><small><i>Word annotation을 Character annotation으로</i></small></figcaption>
</figure>
</div>
<p>그런데, 일반적으로 많은 데이터셋은 character 단위가 아닌 word 단위로 annotation을 해 두었다.
이렇게 character 단위로 box annotation이 되어 있지 않을 경우엔 어떻게 heatmap을 구해야 할까?
이에 대한 답으로 저자는 word 단위 annotation을 자르는 weakly supervised learning 방법을 제시했다.
우선 word 단위로 annotation되어 있는 부분을 잘라 각각의 글자만 남은 이미지로 만들고, 이를 CRAFT 모델에 태운다.
그렇게 되면 region score가 나오는데, 이를 watershed algorithm을 통해 각 글자를 따로따로 감쌀 수 있는 형태로 만들고,
만들어진 mark를 감싸는 character box를 만들었다.</p>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>



<span  class="text-center">
  \[
  s_{conf}(w) = \frac{l(w) - min(l(w), |l(w) - l^{c}(w)|)}{l(w)}
\tag{1}
  \]
</span>

<p>이 방식은 학습이 되어 있지 않은 처음에는 모델이 거의 heatmap 예측을 하지 못해 자칫 잘못된 결과를 만들 수 있는데,
이를 해결하기 위해 예측된 character 개수와 실제 character 개수를 비교해 confidence score를 계산하고,
이를 semi-ground truth값에 반영한다 (1). 만약 원래 6개의 character로 이루어진 단어인데,
이를 5개로 예측했을 경우 confidence score는 &lsquo;이 ground truth는 5/6 확률로 맞다&rsquo; 라는 뜻을 가진 값이 될 것이다.
이 confidence score를 계산해 word annotation이 있는 구역에서는 값을 confidence score로 하고,
이외 구역에서는 1로 하는 confidence map을 (2)와 같이 만들었다.</p>


<span  class="text-center">
  \[
  S_{c}(p) = 
\begin{cases}
    s_{conf}(w) \quad p \in R(w), \\
    1 \qquad\qquad otherwise,
\end{cases}
\tag{2}
  \]
</span>

<h1 id="loss">Loss</h1>
<p>이제 Dataset도 구했고, ground truth heatmap도 계산해냈다. 이제는 학습을 시킬 일만 남았을 것이다.
그런데, 출력되는 output이 총 2개인데, 어떻게 loss 값을 정의해야 할까? 이 문제가 CRAFT 논문에서의 다음 문제가 된다.</p>
<p>사실 큰 문제는 아닌게, 이미 ground truth heatmap도 두 가지를 모두 구해 뒀기 때문에,
두 가지 heatmap (region/affinity)의 pixel-wise loss를 모두 구해서 더하면 된다.
pixel-wise loss를 구할 때는 L2 loss가 사용되었고, 특이한 점으로는 pixel마다 구했던 confidence score를 곱해서 최종 loss로 사용했다.
따라서, Loss 식을 (3) 같이 정리할 수 있다.</p>


<span  class="text-center">
  \[
  L = \Sigma_{p} S_{c}(p) \cdot (||S_{r}(p) - S_{r}^{*}(p)||^{2}_{2} &#43; ||S_{a}(p) - S_{a}^{*}(p)||^{2}_{2})
\tag{3}
  \]
</span>

<h1 id="result">Result</h1>
<p>지금까지 CRAFT 논문에서 제시했던 특이하다 할 만한 내용을 정리해 두었고, 이후 학습이나 inference는 heatmap을 생성하고,
이를 바탕으로 box를 예측하는 예상 가능한 흐름을 따라갔다.
추가로, 연결 상태를 더 잘 예측하기 위한 LinkRefiner 모델을 postprocessing 과정에 사용하기도 했으나, 이 부분은 추후에 다뤄볼 예정이다.
마지막으로, 위와 같은 방법을 사용한 inference 결과는 아래와 같이 나왔다 한다.</p>
<div style="text-align: center;">
<figure >
    
        <img src="/images/paper/craft/craft_4.png" />
    
    <figcaption><small><i>CRAFT 결과</i></small></figcaption>
</figure>
</div>
<h1 id="references">REFERENCES</h1>
<p><a href="https://arxiv.org/pdf/1904.01941.pdf">Character Region Awareness for Text Detection</a></p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>